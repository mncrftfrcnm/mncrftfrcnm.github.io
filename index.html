<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Hugging Face T5-smaller Inference</title>
  <style>
    /* Mobile-first CSS */
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: Arial, sans-serif; padding: 1rem; background: #f4f4f4; }
    .container { max-width: 600px; margin: auto; background: #fff; padding: 1.5rem; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }
    h1 { font-size: 1.5rem; margin-bottom: 1rem; text-align: center; }
    label { display: block; margin-top: 1rem; font-weight: bold; }
    textarea { width: 100%; padding: 0.75rem; margin-top: 0.5rem; border: 1px solid #ccc; border-radius: 0.25rem; font-size: 1rem; }
    button { margin-top: 1rem; padding: 0.75rem 1.25rem; font-size: 1rem; border: none; border-radius: 0.25rem; cursor: pointer; background: #4CAF50; color: white; }
    button:disabled { background: #9E9E9E; cursor: not-allowed; }
    .output { margin-top: 1rem; padding: 1rem; background: #eef; border-radius: 0.25rem; white-space: pre-wrap; }
    .error { color: red; font-weight: bold; }
    @media (min-width: 768px) {
      .container { padding: 2rem; }
      h1 { font-size: 2rem; }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>T5-smaller Inference Demo</h1>
    <!-- Hardcoded model ID -->
    <p>Model: <strong>ShinpacheShimura/t5-smaller</strong></p>
    <label for="prompt-input">Enter Input Text:</label>
    <textarea id="prompt-input" rows="4" placeholder="Type your text here..."></textarea>
    <button id="run-btn">Generate</button>
    <div id="output" class="output"></div>
  </div>

  <script type="module">
    // Using a specific version of Xenova Transformers to avoid path issues
    import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.4.0/dist/transformers.esm.js';

    const MODEL_ID = 'ShinpacheShimura/t5-smaller';  // Hardcoded model identifier
    let nlp;
    const runBtn = document.getElementById('run-btn');
    const promptInput = document.getElementById('prompt-input');
    const outputDiv = document.getElementById('output');

    async function init() {
      runBtn.disabled = true;
      runBtn.textContent = 'Loading Model...';
      try {
        // T5 uses text2text-generation
        nlp = await pipeline('text2text-generation', MODEL_ID);
        runBtn.textContent = 'Generate';
        runBtn.disabled = false;
      } catch (err) {
        console.error('Model load error:', err);
        outputDiv.innerHTML = `<span class="error">Error loading model:</span> ${err.message}`;
      }
    }

    runBtn.addEventListener('click', async () => {
      if (!nlp) return;
      runBtn.disabled = true;
      runBtn.textContent = 'Generating...';
      outputDiv.textContent = '';
      try {
        const prompt = promptInput.value.trim();
        if (!prompt) {
          outputDiv.innerHTML = '<span class="error">Please enter a prompt.</span>';
        } else {
          const result = await nlp(prompt, { max_new_tokens: 50 });
          outputDiv.textContent = result[0].generated_text || result[0].text || JSON.stringify(result[0]);
        }
      } catch (err) {
        console.error('Inference error:', err);
        outputDiv.innerHTML = `<span class="error">Error during generation:</span> ${err.message}`;
      }
      runBtn.disabled = false;
      runBtn.textContent = 'Generate';
    });

    // Kick off model load
    init();
  </script>
</body>
</html>
